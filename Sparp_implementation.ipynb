{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpvF3fi2P5OmYTIs6i2wHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wizorld/sparp_iit/blob/main/Sparp_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UWdW_JibHyh",
        "outputId": "2a19c1ee-82f4-4c8d-a30e-913be5d2b380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.30.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.24.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (10.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.8.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install diffusers transformers\n",
        "!pip install numpy scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gsCTP9XbxJd",
        "outputId": "cb73600a-671a-46f0-a340-34e3295fe2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install huggingface_hub\n",
        "!pip install tqdm\n",
        "!pip install trimesh\n",
        "!pip install pyrender\n",
        "!apt-get update && apt-get install -y xvfb\n",
        "!pip install pyglet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynm4KsSXJHA2",
        "outputId": "7a2c01ee-56b1-498e-c547-79c244f2d525"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.5.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.26.4)\n",
            "Downloading trimesh-4.5.2-py3-none-any.whl (704 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.4/704.4 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.5.2\n",
            "Collecting pyrender\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting freetype-py (from pyrender)\n",
            "  Downloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from pyrender) (2.36.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pyrender) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyrender) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from pyrender) (10.4.0)\n",
            "Collecting pyglet>=1.4.10 (from pyrender)\n",
            "  Downloading pyglet-2.0.18-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting PyOpenGL==3.1.0 (from pyrender)\n",
            "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyrender) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyrender) (1.16.0)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.10/dist-packages (from pyrender) (4.5.2)\n",
            "Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyglet-2.0.18-py3-none-any.whl (941 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m941.1/941.1 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: PyOpenGL\n",
            "  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745193 sha256=e7108a223b86352bd7d612b2a72a34edec97ece61099c3001cce91906346fcc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/3c/d2/1f9533f908d86176637521e533c6cdb2d4e48b59003b5c3f19\n",
            "Successfully built PyOpenGL\n",
            "Installing collected packages: PyOpenGL, pyglet, freetype-py, pyrender\n",
            "  Attempting uninstall: PyOpenGL\n",
            "    Found existing installation: PyOpenGL 3.1.7\n",
            "    Uninstalling PyOpenGL-3.1.7:\n",
            "      Successfully uninstalled PyOpenGL-3.1.7\n",
            "Successfully installed PyOpenGL-3.1.0 freetype-py-2.5.1 pyglet-2.0.18 pyrender-0.1.45\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,611 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,696 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,458 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,353 kB]\n",
            "Fetched 19.0 MB in 4s (4,270 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 7,815 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 7,815 kB in 2s (3,703 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.10/dist-packages (2.0.18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install objaverse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkoeuRvsc-_s",
        "outputId": "456471c8-3669-42a1-e6fb-fdbf1ebc8326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting objaverse\n",
            "  Downloading objaverse-0.1.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from objaverse) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from objaverse) (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from objaverse) (17.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from objaverse) (4.66.6)\n",
            "Collecting loguru (from objaverse)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.10/dist-packages (from objaverse) (2024.10.0)\n",
            "Collecting gputil==1.4.0 (from objaverse)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->objaverse) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->objaverse) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->objaverse) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->objaverse) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->objaverse) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->objaverse) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->objaverse) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->objaverse) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->objaverse) (1.16.0)\n",
            "Downloading objaverse-0.1.7-py3-none-any.whl (32 kB)\n",
            "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=2311ed06919a3b84960316461bd8046c31492ee5af01cbd4ad49823b3c337453\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil, loguru, objaverse\n",
            "Successfully installed gputil-1.4.0 loguru-0.7.2 objaverse-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sin, cos, pi\n",
        "import numpy as np\n",
        "from scipy.spatial.transform import Rotation\n",
        "import shutil\n",
        "\n",
        "class SimpleDataLoader:\n",
        "    def __init__(self,\n",
        "                 data_dir: str = './test_data',\n",
        "                 image_size: int = 512):\n",
        "        print(\"Initializing SimpleDataLoader...\")\n",
        "\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.image_size = image_size\n",
        "\n",
        "        # Create directories\n",
        "        print(\"Creating directories...\")\n",
        "        self.data_dir.mkdir(exist_ok=True, parents=True)\n",
        "        self.image_dir = self.data_dir / 'images'\n",
        "        self.image_dir.mkdir(exist_ok=True)\n",
        "        self.nocs_dir = self.data_dir / 'nocs_maps'\n",
        "        self.nocs_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Initialize dataset\n",
        "        print(\"Initializing dataset...\")\n",
        "        self.dataset = {}\n",
        "\n",
        "        # Initialize or load dataset info\n",
        "        self.dataset_file = self.data_dir / 'dataset_info.json'\n",
        "        if self.dataset_file.exists():\n",
        "            print(\"Loading existing dataset...\")\n",
        "            self._load_dataset()\n",
        "        else:\n",
        "            print(\"No existing dataset found.\")\n",
        "            self._save_dataset()\n",
        "\n",
        "        # Create test data if dataset is empty\n",
        "        if not self.dataset:\n",
        "            print(\"Creating new test data...\")\n",
        "            self._create_test_data()\n",
        "\n",
        "        print(f\"Initialization complete. Dataset contains {len(self.dataset)} objects.\")\n",
        "\n",
        "\n",
        "    def _generate_nocs_map(self, shape_type: str, view_angle: float, size: int) -> Image.Image:\n",
        "        \"\"\"Generate NOCS map for a given shape and view angle\"\"\"\n",
        "        nocs_map = np.zeros((size, size, 3), dtype=np.float32)\n",
        "        center_x = size // 2\n",
        "        center_y = size // 2\n",
        "        shape_size = size // 3\n",
        "\n",
        "        if shape_type == 'cube':\n",
        "            # Generate cube NOCS coordinates\n",
        "            for x in range(size):\n",
        "                for y in range(size):\n",
        "                    # Convert to local coordinates\n",
        "                    local_x = (x - center_x) / shape_size\n",
        "                    local_y = (y - center_y) / shape_size\n",
        "\n",
        "                    # Apply view rotation\n",
        "                    rot_matrix = np.array([\n",
        "                        [cos(view_angle), -sin(view_angle)],\n",
        "                        [sin(view_angle), cos(view_angle)]\n",
        "                    ])\n",
        "                    rotated = np.dot(rot_matrix, np.array([local_x, local_y]))\n",
        "                    local_x, local_y = rotated\n",
        "\n",
        "                    # Check if point is inside cube\n",
        "                    if abs(local_x) <= 1 and abs(local_y) <= 1:\n",
        "                        # Normalize coordinates to [0, 1]\n",
        "                        nocs_x = (local_x + 1) / 2\n",
        "                        nocs_y = (local_y + 1) / 2\n",
        "                        nocs_z = 0.5  # Middle of the cube\n",
        "\n",
        "                        nocs_map[y, x] = [nocs_x, nocs_y, nocs_z]\n",
        "\n",
        "        elif shape_type == 'cylinder':\n",
        "            # Generate cylinder NOCS coordinates\n",
        "            for x in range(size):\n",
        "                for y in range(size):\n",
        "                    local_x = (x - center_x) / shape_size\n",
        "                    local_y = (y - center_y) / shape_size\n",
        "\n",
        "                    # Calculate radius and angle for cylinder\n",
        "                    radius = np.sqrt(local_x**2 + local_y**2)\n",
        "                    if radius <= 1:\n",
        "                        angle = np.arctan2(local_y, local_x)\n",
        "\n",
        "                        # Convert to NOCS coordinates\n",
        "                        nocs_x = (radius * np.cos(angle + view_angle) + 1) / 2\n",
        "                        nocs_y = (radius * np.sin(angle + view_angle) + 1) / 2\n",
        "                        nocs_z = 0.5  # Middle of cylinder\n",
        "\n",
        "                        nocs_map[y, x] = [nocs_x, nocs_y, nocs_z]\n",
        "\n",
        "        elif shape_type == 'pyramid':\n",
        "            # Generate pyramid NOCS coordinates\n",
        "            height = shape_size * 2\n",
        "            base_width = shape_size * 2\n",
        "\n",
        "            for x in range(size):\n",
        "                for y in range(size):\n",
        "                    local_x = (x - center_x) / (base_width/2)\n",
        "                    local_y = (y - center_y) / height\n",
        "\n",
        "                    # Apply view rotation\n",
        "                    rot_matrix = np.array([\n",
        "                        [cos(view_angle), -sin(view_angle)],\n",
        "                        [sin(view_angle), cos(view_angle)]\n",
        "                    ])\n",
        "                    rotated = np.dot(rot_matrix, np.array([local_x, local_y]))\n",
        "                    local_x, local_y = rotated\n",
        "\n",
        "                    # Check if point is inside pyramid\n",
        "                    if abs(local_x) <= (1 - abs(local_y)) and abs(local_y) <= 1:\n",
        "                        nocs_x = (local_x + 1) / 2\n",
        "                        nocs_y = (local_y + 1) / 2\n",
        "                        nocs_z = (1 - abs(local_y)) / 2  # Height decreases with y\n",
        "\n",
        "                        nocs_map[y, x] = [nocs_x, nocs_y, nocs_z]\n",
        "\n",
        "        # Convert to PIL Image\n",
        "        nocs_map = (nocs_map * 255).astype(np.uint8)\n",
        "        return Image.fromarray(nocs_map)\n",
        "\n",
        "\n",
        "    def _create_gradient_texture(self, size):\n",
        "        \"\"\"Create a gradient texture\"\"\"\n",
        "        img = Image.new('RGB', (size, size))\n",
        "        pixels = img.load()\n",
        "        for i in range(size):\n",
        "            for j in range(size):\n",
        "                r = int((i / size) * 255)\n",
        "                g = int((j / size) * 255)\n",
        "                b = int(((i + j) / (2 * size)) * 255)\n",
        "                pixels[i, j] = (r, g, b)\n",
        "        return img\n",
        "\n",
        "    def _create_pattern_texture(self, size, pattern_type='grid'):\n",
        "        \"\"\"Create a patterned texture\"\"\"\n",
        "        img = Image.new('RGB', (size, size), 'white')\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        if pattern_type == 'grid':\n",
        "            # Draw grid lines\n",
        "            spacing = size // 8\n",
        "            for i in range(0, size, spacing):\n",
        "                draw.line([(i, 0), (i, size)], fill='black', width=2)\n",
        "                draw.line([(0, i), (size, i)], fill='black', width=2)\n",
        "\n",
        "        elif pattern_type == 'dots':\n",
        "            # Draw dots pattern\n",
        "            spacing = size // 8\n",
        "            dot_size = spacing // 4\n",
        "            for i in range(0, size, spacing):\n",
        "                for j in range(0, size, spacing):\n",
        "                    draw.ellipse([i-dot_size, j-dot_size, i+dot_size, j+dot_size],\n",
        "                               fill='black')\n",
        "\n",
        "        elif pattern_type == 'stripes':\n",
        "            # Draw diagonal stripes\n",
        "            spacing = size // 16\n",
        "            for i in range(-size, size*2, spacing):\n",
        "                draw.line([(i, 0), (i+size, size)], fill='black', width=2)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def _apply_texture_to_shape(self, img, shape_mask, texture):\n",
        "        \"\"\"Apply texture to a shape using a mask\"\"\"\n",
        "        # Convert images to numpy arrays for easier manipulation\n",
        "        img_array = np.array(img)\n",
        "        mask_array = np.array(shape_mask)\n",
        "        texture_array = np.array(texture)\n",
        "\n",
        "        # Apply texture only where mask is non-zero\n",
        "        for c in range(3):  # For each color channel\n",
        "            img_array[:,:,c] = np.where(mask_array == 255,\n",
        "                                      texture_array[:,:,c],\n",
        "                                      img_array[:,:,c])\n",
        "\n",
        "        return Image.fromarray(img_array)\n",
        "\n",
        "    def _create_textured_shape(self, size, shape_type, view_angle=0):\n",
        "        \"\"\"Create a shape with texture\"\"\"\n",
        "        # Create base image and mask\n",
        "        img = Image.new('RGB', (size, size), 'white')\n",
        "        mask = Image.new('L', (size, size), 0)\n",
        "        draw = ImageDraw.Draw(mask)\n",
        "\n",
        "        center_x = size // 2\n",
        "        center_y = size // 2\n",
        "        shape_size = size // 3\n",
        "\n",
        "        # Create shape mask with rotation\n",
        "        if shape_type == 'cube':\n",
        "            # Draw a cube-like shape\n",
        "            points = [\n",
        "                (center_x - shape_size + shape_size * cos(view_angle),\n",
        "                 center_y - shape_size + shape_size * sin(view_angle)),\n",
        "                (center_x + shape_size + shape_size * cos(view_angle),\n",
        "                 center_y - shape_size + shape_size * sin(view_angle)),\n",
        "                (center_x + shape_size - shape_size * sin(view_angle),\n",
        "                 center_y + shape_size + shape_size * cos(view_angle)),\n",
        "                (center_x - shape_size - shape_size * sin(view_angle),\n",
        "                 center_y + shape_size + shape_size * cos(view_angle))\n",
        "            ]\n",
        "            draw.polygon(points, fill=255)\n",
        "\n",
        "        elif shape_type == 'cylinder':\n",
        "            # Draw a cylinder-like shape\n",
        "            draw.ellipse([center_x - shape_size, center_y - shape_size//2,\n",
        "                         center_x + shape_size, center_y + shape_size//2], fill=255)\n",
        "\n",
        "        elif shape_type == 'pyramid':\n",
        "            # Draw a pyramid-like shape\n",
        "            height = shape_size * 2\n",
        "            base_width = shape_size * 2\n",
        "            points = [\n",
        "                (center_x, center_y - height//2),  # Top\n",
        "                (center_x - base_width//2, center_y + height//2),  # Bottom left\n",
        "                (center_x + base_width//2, center_y + height//2)   # Bottom right\n",
        "            ]\n",
        "            draw.polygon(points, fill=255)\n",
        "\n",
        "        # Create and apply texture\n",
        "        patterns = ['grid', 'dots', 'stripes']\n",
        "        texture = self._create_pattern_texture(size, random.choice(patterns))\n",
        "\n",
        "        # Apply a color tint\n",
        "        tint = Image.new('RGB', (size, size),\n",
        "                        (random.randint(50, 200),\n",
        "                         random.randint(50, 200),\n",
        "                         random.randint(50, 200)))\n",
        "        texture = Image.blend(texture, tint, 0.5)\n",
        "\n",
        "        # Apply texture to shape\n",
        "        textured_img = self._apply_texture_to_shape(img, mask, texture)\n",
        "\n",
        "        return textured_img\n",
        "\n",
        "    def _create_test_data(self):\n",
        "      \"\"\"Create test data with textured shapes and NOCS maps\"\"\"\n",
        "      print(\"Creating test dataset...\")\n",
        "\n",
        "      shapes = ['cube', 'cylinder', 'pyramid']\n",
        "\n",
        "      for obj_idx, shape_type in enumerate(shapes):\n",
        "          try:\n",
        "              obj_id = f\"test_object_{obj_idx}\"\n",
        "              print(f\"\\nProcessing {shape_type} (ID: {obj_id})...\")\n",
        "\n",
        "              object_data = {\n",
        "                  'uid': obj_id,\n",
        "                  'category': shape_type,\n",
        "                  'images': [],\n",
        "                  'nocs_maps': []  # Ensure this is initialized\n",
        "              }\n",
        "\n",
        "              # Create 6 views with different angles\n",
        "              for view_idx in range(6):\n",
        "                  print(f\"Creating view {view_idx}\")\n",
        "                  image_path = self.image_dir / f\"{obj_id}_view_{view_idx}.jpg\"\n",
        "                  nocs_path = self.nocs_dir / f\"{obj_id}_nocs_{view_idx}.png\"\n",
        "\n",
        "                  view_angle = (view_idx * 2 * pi) / 6\n",
        "\n",
        "                  # Create textured view\n",
        "                  if not image_path.exists():\n",
        "                      img = self._create_textured_shape(self.image_size,\n",
        "                                                      shape_type,\n",
        "                                                      view_angle)\n",
        "                      img.save(image_path)\n",
        "                      print(f\"Saved image: {image_path}\")\n",
        "\n",
        "                  # Create NOCS map\n",
        "                  if not nocs_path.exists():\n",
        "                      nocs_map = self._generate_nocs_map(shape_type,\n",
        "                                                      view_angle,\n",
        "                                                      self.image_size)\n",
        "                      nocs_map.save(nocs_path)\n",
        "                      print(f\"Saved NOCS map: {nocs_path}\")\n",
        "\n",
        "                  # Store paths in object data\n",
        "                  object_data['images'].append(str(image_path))\n",
        "                  object_data['nocs_maps'].append(str(nocs_path))\n",
        "\n",
        "              # Save object data to dataset\n",
        "              self.dataset[obj_id] = object_data\n",
        "              # Save after each object in case of errors\n",
        "              self._save_dataset()\n",
        "              print(f\"Successfully processed {shape_type}\")\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error processing shape {shape_type}: {str(e)}\")\n",
        "              continue\n",
        "\n",
        "      print(f\"\\nCreated {len(self.dataset)} test objects with NOCS maps\")\n",
        "\n",
        "\n",
        "    def _save_dataset(self):\n",
        "        print(f\"Saving dataset with {len(self.dataset)} objects...\")\n",
        "        with open(self.dataset_file, 'w') as f:\n",
        "            json.dump(self.dataset, f, indent=2)\n",
        "        print(\"Dataset saved successfully.\")\n",
        "\n",
        "    def _load_dataset(self):\n",
        "      \"\"\"Load dataset with error handling\"\"\"\n",
        "      try:\n",
        "          print(\"Loading dataset from file...\")\n",
        "          with open(self.dataset_file, 'r') as f:\n",
        "              loaded_data = json.load(f)\n",
        "\n",
        "          # Verify and fix data structure if needed\n",
        "          for obj_id, obj_data in loaded_data.items():\n",
        "              if 'nocs_maps' not in obj_data:\n",
        "                  print(f\"Fixing missing nocs_maps for {obj_id}\")\n",
        "                  obj_data['nocs_maps'] = []\n",
        "                  # Generate NOCS maps for existing images\n",
        "                  for idx, img_path in enumerate(obj_data['images']):\n",
        "                      nocs_path = self.nocs_dir / f\"{obj_id}_nocs_{idx}.png\"\n",
        "                      if not nocs_path.exists():\n",
        "                          shape_type = obj_data['category']\n",
        "                          view_angle = (idx * 2 * pi) / 6\n",
        "                          nocs_map = self._generate_nocs_map(shape_type,\n",
        "                                                          view_angle,\n",
        "                                                          self.image_size)\n",
        "                          nocs_map.save(nocs_path)\n",
        "                      obj_data['nocs_maps'].append(str(nocs_path))\n",
        "\n",
        "          self.dataset = loaded_data\n",
        "          print(f\"Dataset loaded successfully with {len(self.dataset)} objects.\")\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error loading dataset: {str(e)}\")\n",
        "          print(\"Creating new dataset...\")\n",
        "          self.dataset = {}\n",
        "          self._create_test_data()\n",
        "\n",
        "    def load_object_views(self, uid: str) -> tuple:\n",
        "        \"\"\"Load all views and NOCS maps for a specific object\"\"\"\n",
        "        if uid not in self.dataset:\n",
        "            raise ValueError(f\"Object {uid} not found in dataset\")\n",
        "\n",
        "        images = []\n",
        "        nocs_maps = []\n",
        "\n",
        "        for img_path, nocs_path in zip(self.dataset[uid]['images'],\n",
        "                                     self.dataset[uid]['nocs_maps']):\n",
        "            images.append(Image.open(img_path))\n",
        "            nocs_maps.append(Image.open(nocs_path))\n",
        "\n",
        "        return images, nocs_maps\n",
        "\n",
        "    def get_random_object(self) -> tuple:\n",
        "        \"\"\"Get a random object and its views\"\"\"\n",
        "        if not self.dataset:\n",
        "            raise ValueError(\"No objects in dataset\")\n",
        "\n",
        "        uid = random.choice(list(self.dataset.keys()))\n",
        "        images = self.load_object_views(uid)\n",
        "        return uid, images\n",
        "\n",
        "    def estimate_poses(self):\n",
        "      \"\"\"\n",
        "      Estimate poses for all views of all objects\n",
        "      \"\"\"\n",
        "      pose_estimator = PoseEstimator(self.image_size)\n",
        "\n",
        "      for uid in self.dataset.keys():\n",
        "          try:\n",
        "              images, nocs_maps = self.load_object_views(uid)\n",
        "\n",
        "              # Store poses for this object\n",
        "              poses = []\n",
        "\n",
        "              for img, nocs in zip(images, nocs_maps):\n",
        "                  try:\n",
        "                      # Estimate pose\n",
        "                      rotation, translation = pose_estimator.estimate_pose(np.array(img), np.array(nocs))\n",
        "\n",
        "                      # Create visualization\n",
        "                      vis_img = pose_estimator.visualize_pose_estimation(\n",
        "                          np.array(img),\n",
        "                          np.array(nocs),\n",
        "                          rotation,\n",
        "                          translation\n",
        "                      )\n",
        "\n",
        "                      # Store pose data\n",
        "                      poses.append({\n",
        "                          'rotation': rotation.tolist(),\n",
        "                          'translation': translation.tolist()\n",
        "                      })\n",
        "\n",
        "                      # Visualize results\n",
        "                      plt.figure(figsize=(15, 5))\n",
        "\n",
        "                      plt.subplot(131)\n",
        "                      plt.imshow(img)\n",
        "                      plt.title('Original Image')\n",
        "                      plt.axis('off')\n",
        "\n",
        "                      plt.subplot(132)\n",
        "                      plt.imshow(nocs)\n",
        "                      plt.title('NOCS Map')\n",
        "                      plt.axis('off')\n",
        "\n",
        "                      plt.subplot(133)\n",
        "                      plt.imshow(vis_img)\n",
        "                      plt.title('Pose Estimation')\n",
        "                      plt.axis('off')\n",
        "\n",
        "                      plt.suptitle(f'Object {uid} - Pose Estimation Results')\n",
        "                      plt.show()\n",
        "\n",
        "                  except Exception as e:\n",
        "                      print(f\"Error estimating pose for view: {str(e)}\")\n",
        "                      poses.append(None)\n",
        "\n",
        "              # Store poses in dataset\n",
        "              self.dataset[uid]['poses'] = poses\n",
        "              self._save_dataset()\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error processing object {uid}: {str(e)}\")\n",
        "              continue\n",
        "\n",
        "    def generate_novel_views(self, num_views=8):\n",
        "      \"\"\"Generate novel views for each object\"\"\"\n",
        "      trainer = MultiViewTrainer(self)\n",
        "      print(\"Training multi-view generation model...\")\n",
        "      trainer.train(num_epochs=100)\n",
        "\n",
        "      print(\"\\nGenerating novel views...\")\n",
        "      for uid in self.dataset:\n",
        "          try:\n",
        "              # Get source image and pose\n",
        "              images, _ = self.load_object_views(uid)\n",
        "              source_image = images[0]\n",
        "\n",
        "              # Generate novel views by rotating around the object\n",
        "              novel_views = []\n",
        "              for i in range(num_views):\n",
        "                  angle = (i * 2 * np.pi) / num_views\n",
        "                  target_pose = np.array([\n",
        "                      np.cos(angle), np.sin(angle), 0,  # Rotation\n",
        "                      0, 0, 2  # Translation\n",
        "                  ])\n",
        "\n",
        "                  novel_view = trainer.generate_novel_view(source_image, target_pose)\n",
        "                  novel_views.append(novel_view)\n",
        "\n",
        "              # Visualize results\n",
        "              plt.figure(figsize=(20, 4))\n",
        "              for i, view in enumerate(novel_views):\n",
        "                  plt.subplot(1, num_views, i + 1)\n",
        "                  plt.imshow(view)\n",
        "                  plt.axis('off')\n",
        "                  plt.title(f'View {i+1}')\n",
        "              plt.suptitle(f'Novel Views for Object {uid}')\n",
        "              plt.show()\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error generating novel views for object {uid}: {str(e)}\")\n",
        "              continue\n",
        "\n",
        "def visualize_object_data(images, nocs_maps, uid):\n",
        "    \"\"\"Visualize both images and NOCS maps\"\"\"\n",
        "    n_views = len(images)\n",
        "    plt.figure(figsize=(20, 8))\n",
        "\n",
        "    # Show original images\n",
        "    for i in range(n_views):\n",
        "        plt.subplot(2, n_views, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'View {i+1}')\n",
        "\n",
        "    # Show NOCS maps\n",
        "    for i in range(n_views):\n",
        "        plt.subplot(2, n_views, n_views + i + 1)\n",
        "        plt.imshow(nocs_maps[i])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'NOCS {i+1}')\n",
        "\n",
        "    plt.suptitle(f'Object ID: {uid}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def visualize_views(images, uid):\n",
        "    \"\"\"Visualize multiple views of an object\"\"\"\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, img in enumerate(images):\n",
        "        plt.subplot(1, len(images), i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'View {i+1}')\n",
        "    plt.suptitle(f'Object ID: {uid}')\n",
        "    plt.show()\n",
        "\n",
        "# Test the implementation\n",
        "def setup_and_test():\n",
        "    \"\"\"Setup and test the data loader with error handling\"\"\"\n",
        "    try:\n",
        "        print(\"Creating data loader...\")\n",
        "        data_loader = SimpleDataLoader(image_size=512)\n",
        "\n",
        "        if not data_loader.dataset:\n",
        "            print(\"Error: dataset is empty\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Dataset initialized with {len(data_loader.dataset)} objects\")\n",
        "\n",
        "        # Try loading first object\n",
        "        uids = list(data_loader.dataset.keys())\n",
        "        if not uids:\n",
        "            print(\"Error: No objects found in dataset\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Found objects with IDs: {uids}\")\n",
        "\n",
        "        for uid in uids:\n",
        "            try:\n",
        "                print(f\"\\nLoading object {uid}...\")\n",
        "\n",
        "                # Verify object data structure\n",
        "                obj_data = data_loader.dataset[uid]\n",
        "                print(f\"Category: {obj_data['category']}\")\n",
        "                print(f\"Number of images: {len(obj_data['images'])}\")\n",
        "                print(f\"Number of NOCS maps: {len(obj_data['nocs_maps'])}\")\n",
        "\n",
        "                images, nocs_maps = data_loader.load_object_views(uid)\n",
        "                print(f\"Loaded {len(images)} images and {len(nocs_maps)} NOCS maps\")\n",
        "\n",
        "                visualize_object_data(images, nocs_maps, uid)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing object {uid}: {str(e)}\")\n",
        "                print(\"Object data:\", data_loader.dataset[uid])\n",
        "                continue\n",
        "\n",
        "        print(\"Success!\")\n",
        "        return data_loader\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during setup: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# Main execution\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"Starting test...\")\n",
        "\n",
        "#     # Clear the matplotlib plots\n",
        "#     plt.close('all')\n",
        "\n",
        "#     # Run setup and test with error handling\n",
        "#     try:\n",
        "#         data_dir = Path('./test_data')\n",
        "#         if data_dir.exists():\n",
        "#             shutil.rmtree(data_dir)\n",
        "#         data_loader = setup_and_test()\n",
        "\n",
        "#         # if data_loader is None:\n",
        "#         #     print(\"Failed to initialize data loader\")\n",
        "#         # else:\n",
        "#         #     print(\"\\nData loader initialized successfully\")\n",
        "#         #     print(f\"Number of objects: {len(data_loader.dataset)}\")\n",
        "\n",
        "#         #     # Try to show one object\n",
        "#         #     if len(data_loader.dataset) > 0:\n",
        "#         #         uid = list(data_loader.dataset.keys())[0]\n",
        "#         #         print(f\"\\nTrying to show first object ({uid})...\")\n",
        "#         #         images, nocs_maps = data_loader.load_object_views(uid)\n",
        "#         #         visualize_object_data(images, nocs_maps, uid)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in main execution: {str(e)}\")\n",
        "#         import traceback\n",
        "#         traceback.print_exc()"
      ],
      "metadata": {
        "id": "3_5wrwE9cT-t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.spatial.transform import Rotation\n",
        "from typing import Tuple, List\n",
        "\n",
        "class PoseEstimator:\n",
        "    def __init__(self, image_size: int = 512):\n",
        "        self.image_size = image_size\n",
        "        # Define camera intrinsics (can be adjusted based on your needs)\n",
        "        self.focal_length = image_size\n",
        "        self.camera_matrix = np.array([\n",
        "            [self.focal_length, 0, image_size/2],\n",
        "            [0, self.focal_length, image_size/2],\n",
        "            [0, 0, 1]\n",
        "        ])\n",
        "\n",
        "    def extract_correspondences(self,\n",
        "                              rgb_image: np.ndarray,\n",
        "                              nocs_map: np.ndarray,\n",
        "                              min_points: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Extract corresponding points between RGB image and NOCS map\n",
        "        \"\"\"\n",
        "        # Convert images to numpy if they're PIL\n",
        "        if not isinstance(rgb_image, np.ndarray):\n",
        "            rgb_image = np.array(rgb_image)\n",
        "        if not isinstance(nocs_map, np.ndarray):\n",
        "            nocs_map = np.array(nocs_map)\n",
        "\n",
        "        # Find features in RGB image\n",
        "        orb = cv2.ORB_create(nfeatures=1000)\n",
        "        keypoints = orb.detect(rgb_image, None)\n",
        "\n",
        "        # Get 2D points from keypoints\n",
        "        points_2d = []\n",
        "        points_3d = []\n",
        "\n",
        "        for kp in keypoints:\n",
        "            x, y = map(int, kp.pt)\n",
        "\n",
        "            # Get corresponding 3D point from NOCS map\n",
        "            nocs_point = nocs_map[y, x] / 255.0  # Normalize to [0,1]\n",
        "\n",
        "            # Check if point is valid (not background)\n",
        "            if np.any(nocs_point > 0):\n",
        "                # Convert NOCS coordinates to actual 3D coordinates\n",
        "                x3d = nocs_point[0] * 2 - 1  # Convert to [-1, 1]\n",
        "                y3d = nocs_point[1] * 2 - 1\n",
        "                z3d = nocs_point[2] * 2 - 1\n",
        "\n",
        "                points_2d.append([x, y])\n",
        "                points_3d.append([x3d, y3d, z3d])\n",
        "\n",
        "        points_2d = np.array(points_2d, dtype=np.float32)\n",
        "        points_3d = np.array(points_3d, dtype=np.float32)\n",
        "\n",
        "        if len(points_2d) < min_points:\n",
        "            raise ValueError(f\"Not enough correspondences found: {len(points_2d)} < {min_points}\")\n",
        "\n",
        "        return points_2d, points_3d\n",
        "\n",
        "    def estimate_pose(self,\n",
        "                     rgb_image: np.ndarray,\n",
        "                     nocs_map: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Estimate camera pose from RGB image and NOCS map\n",
        "        Returns: rotation matrix, translation vector\n",
        "        \"\"\"\n",
        "        # Get corresponding points\n",
        "        points_2d, points_3d = self.extract_correspondences(rgb_image, nocs_map)\n",
        "\n",
        "        # Estimate pose using PnP\n",
        "        success, rvec, tvec = cv2.solvePnP(\n",
        "            points_3d,\n",
        "            points_2d,\n",
        "            self.camera_matrix,\n",
        "            None,\n",
        "            flags=cv2.SOLVEPNP_ITERATIVE\n",
        "        )\n",
        "\n",
        "        if not success:\n",
        "            raise RuntimeError(\"Failed to estimate pose\")\n",
        "\n",
        "        # Convert rotation vector to matrix\n",
        "        rmat, _ = cv2.Rodrigues(rvec)\n",
        "\n",
        "        return rmat, tvec\n",
        "\n",
        "    def visualize_pose_estimation(self,\n",
        "                                rgb_image: np.ndarray,\n",
        "                                nocs_map: np.ndarray,\n",
        "                                rotation: np.ndarray,\n",
        "                                translation: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Visualize pose estimation results\n",
        "        \"\"\"\n",
        "        # Convert images to numpy if they're PIL\n",
        "        if not isinstance(rgb_image, np.ndarray):\n",
        "            rgb_image = np.array(rgb_image)\n",
        "\n",
        "        # Create visualization image\n",
        "        vis_img = rgb_image.copy()\n",
        "\n",
        "        # Draw coordinate axes\n",
        "        axis_length = 100\n",
        "        axis_points = np.float32([[0,0,0], [1,0,0], [0,1,0], [0,0,1]]) * axis_length\n",
        "\n",
        "        # Project 3D axis points to 2D\n",
        "        axis_2d, _ = cv2.projectPoints(\n",
        "            axis_points,\n",
        "            cv2.Rodrigues(rotation)[0],\n",
        "            translation,\n",
        "            self.camera_matrix,\n",
        "            None\n",
        "        )\n",
        "\n",
        "        # Draw axes\n",
        "        origin = tuple(map(int, axis_2d[0].ravel()))\n",
        "        vis_img = cv2.line(vis_img, origin, tuple(map(int, axis_2d[1].ravel())), (0,0,255), 3)  # X-axis (red)\n",
        "        vis_img = cv2.line(vis_img, origin, tuple(map(int, axis_2d[2].ravel())), (0,255,0), 3)  # Y-axis (green)\n",
        "        vis_img = cv2.line(vis_img, origin, tuple(map(int, axis_2d[3].ravel())), (255,0,0), 3)  # Z-axis (blue)\n",
        "\n",
        "        return vis_img\n",
        "\n",
        "# Add this to your SimpleDataLoader class\n",
        "def estimate_poses(self):\n",
        "    \"\"\"\n",
        "    Estimate poses for all views of all objects\n",
        "    \"\"\"\n",
        "    pose_estimator = PoseEstimator(self.image_size)\n",
        "\n",
        "    for uid in self.dataset.keys():\n",
        "        try:\n",
        "            images, nocs_maps = self.load_object_views(uid)\n",
        "\n",
        "            # Store poses for this object\n",
        "            poses = []\n",
        "\n",
        "            for img, nocs in zip(images, nocs_maps):\n",
        "                try:\n",
        "                    # Estimate pose\n",
        "                    rotation, translation = pose_estimator.estimate_pose(np.array(img), np.array(nocs))\n",
        "\n",
        "                    # Create visualization\n",
        "                    vis_img = pose_estimator.visualize_pose_estimation(\n",
        "                        np.array(img),\n",
        "                        np.array(nocs),\n",
        "                        rotation,\n",
        "                        translation\n",
        "                    )\n",
        "\n",
        "                    # Store pose data\n",
        "                    poses.append({\n",
        "                        'rotation': rotation.tolist(),\n",
        "                        'translation': translation.tolist()\n",
        "                    })\n",
        "\n",
        "                    # Visualize results\n",
        "                    plt.figure(figsize=(15, 5))\n",
        "\n",
        "                    plt.subplot(131)\n",
        "                    plt.imshow(img)\n",
        "                    plt.title('Original Image')\n",
        "                    plt.axis('off')\n",
        "\n",
        "                    plt.subplot(132)\n",
        "                    plt.imshow(nocs)\n",
        "                    plt.title('NOCS Map')\n",
        "                    plt.axis('off')\n",
        "\n",
        "                    plt.subplot(133)\n",
        "                    plt.imshow(vis_img)\n",
        "                    plt.title('Pose Estimation')\n",
        "                    plt.axis('off')\n",
        "\n",
        "                    plt.suptitle(f'Object {uid} - Pose Estimation Results')\n",
        "                    plt.show()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error estimating pose for view: {str(e)}\")\n",
        "                    poses.append(None)\n",
        "\n",
        "            # Store poses in dataset\n",
        "            self.dataset[uid]['poses'] = poses\n",
        "            self._save_dataset()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing object {uid}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "# # Main execution\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"Starting test...\")\n",
        "\n",
        "#     # Clear the matplotlib plots\n",
        "#     plt.close('all')\n",
        "\n",
        "#     # Run setup and test with error handling\n",
        "#     try:\n",
        "#         data_dir = Path('./test_data')\n",
        "#         if data_dir.exists():\n",
        "#             shutil.rmtree(data_dir)\n",
        "#         data_loader = setup_and_test()\n",
        "\n",
        "#         if data_loader is None:\n",
        "#             print(\"Failed to initialize data loader\")\n",
        "#         else:\n",
        "#             if data_loader is not None:\n",
        "#               # Estimate poses for all objects\n",
        "#               print(\"\\nEstimating poses...\")\n",
        "#               data_loader.estimate_poses()\n",
        "\n",
        "#               # You can access the poses through the dataset\n",
        "#               for uid in data_loader.dataset:\n",
        "#                   poses = data_loader.dataset[uid].get('poses', [])\n",
        "#                   print(f\"\\nObject {uid} poses:\")\n",
        "#                   for i, pose in enumerate(poses):\n",
        "#                       if pose:\n",
        "#                           print(f\"View {i}:\")\n",
        "#                           print(f\"Rotation:\\n{np.array(pose['rotation'])}\")\n",
        "#                           print(f\"Translation:\\n{np.array(pose['translation'])}\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in main execution: {str(e)}\")\n",
        "#         import traceback\n",
        "#         traceback.print_exc()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H0hSA_Qr5YQi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# First, let's test if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class MultiViewGenerator(nn.Module):\n",
        "    def __init__(self, latent_dim=256):\n",
        "        super(MultiViewGenerator, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(512, latent_dim, 4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "        # Pose encoder\n",
        "        self.pose_encoder = nn.Sequential(\n",
        "            nn.Linear(6, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim * 2, 512, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, target_pose):\n",
        "        img_features = self.encoder(x)\n",
        "        pose_features = self.pose_encoder(target_pose)\n",
        "        pose_features = pose_features.view(-1, pose_features.size(1), 1, 1)\n",
        "        pose_features = pose_features.expand(-1, -1, img_features.size(2), img_features.size(3))\n",
        "        combined_features = torch.cat([img_features, pose_features], dim=1)\n",
        "        return self.decoder(combined_features)\n",
        "\n",
        "class MultiViewDataset(Dataset):\n",
        "    def __init__(self, data_loader, transform=None):\n",
        "        self.data_loader = data_loader\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self._prepare_dataset()\n",
        "\n",
        "    def _prepare_dataset(self):\n",
        "        for uid in self.data_loader.dataset:\n",
        "            images = []\n",
        "            poses = []\n",
        "\n",
        "            obj_data = self.data_loader.dataset[uid]\n",
        "            for img_path, pose_data in zip(obj_data['images'], obj_data.get('poses', [])):\n",
        "                if pose_data is not None:\n",
        "                    img = Image.open(img_path)\n",
        "                    if self.transform:\n",
        "                        img = self.transform(img)\n",
        "\n",
        "                    rotation = np.array(pose_data['rotation'])\n",
        "                    translation = np.array(pose_data['translation'])\n",
        "                    pose_vector = np.concatenate([\n",
        "                        rotation.flatten()[:3],\n",
        "                        translation.flatten()\n",
        "                    ])\n",
        "\n",
        "                    images.append(img)\n",
        "                    poses.append(pose_vector)\n",
        "\n",
        "            for i in range(len(images)):\n",
        "                for j in range(len(images)):\n",
        "                    if i != j:\n",
        "                        self.samples.append({\n",
        "                            'source_image': images[i],\n",
        "                            'source_pose': poses[i],\n",
        "                            'target_pose': poses[j],\n",
        "                            'target_image': images[j]\n",
        "                        })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        return {\n",
        "            'source_image': sample['source_image'],\n",
        "            'source_pose': torch.FloatTensor(sample['source_pose']),\n",
        "            'target_pose': torch.FloatTensor(sample['target_pose']),\n",
        "            'target_image': sample['target_image']\n",
        "        }\n",
        "\n",
        "class MultiViewTrainer:\n",
        "    def __init__(self, data_loader, device=device):\n",
        "        self.data_loader = data_loader\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize model\n",
        "        self.model = MultiViewGenerator().to(device)\n",
        "\n",
        "        # Initialize transforms\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((512, 512)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        # Initialize dataset\n",
        "        print(\"Initializing dataset...\")\n",
        "        self.dataset = MultiViewDataset(data_loader, self.transform)\n",
        "        print(f\"Dataset size: {len(self.dataset)} pairs\")\n",
        "\n",
        "        # Initialize data loader\n",
        "        self.train_loader = DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=4,\n",
        "            shuffle=True,\n",
        "            num_workers=0  # Changed to 0 to avoid potential multiprocessing issues\n",
        "        )\n",
        "\n",
        "        # Initialize optimizer\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0002)\n",
        "\n",
        "        # Loss functions\n",
        "        self.reconstruction_loss = nn.L1Loss()\n",
        "        self.perceptual_loss = self._get_perceptual_loss()\n",
        "\n",
        "    def _get_perceptual_loss(self):\n",
        "        vgg = torchvision.models.vgg16(pretrained=True).features[:16]\n",
        "        vgg = vgg.to(self.device)\n",
        "        for param in vgg.parameters():\n",
        "            param.requires_grad = False\n",
        "        return vgg\n",
        "\n",
        "    def train(self, num_epochs=100):\n",
        "        print(\"Starting training...\")\n",
        "        for epoch in range(num_epochs):\n",
        "            total_loss = 0\n",
        "            for batch in tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "                source_images = batch['source_image'].to(self.device)\n",
        "                target_poses = batch['target_pose'].to(self.device)\n",
        "                target_images = batch['target_image'].to(self.device)\n",
        "\n",
        "                generated_images = self.model(source_images, target_poses)\n",
        "\n",
        "                recon_loss = self.reconstruction_loss(generated_images, target_images)\n",
        "\n",
        "                gen_features = self.perceptual_loss(generated_images)\n",
        "                target_features = self.perceptual_loss(target_images)\n",
        "                percep_loss = self.reconstruction_loss(gen_features, target_features)\n",
        "\n",
        "                loss = recon_loss + 0.1 * percep_loss\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(self.train_loader)\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                self.visualize_results()\n",
        "\n",
        "    def visualize_results(self):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            batch = next(iter(self.train_loader))\n",
        "            source_images = batch['source_image'].to(self.device)\n",
        "            target_poses = batch['target_pose'].to(self.device)\n",
        "            target_images = batch['target_image'].to(self.device)\n",
        "\n",
        "            generated_images = self.model(source_images, target_poses)\n",
        "\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            for i in range(min(4, len(source_images))):\n",
        "                plt.subplot(3, 4, i + 1)\n",
        "                self._show_tensor_image(source_images[i])\n",
        "                plt.title('Source')\n",
        "\n",
        "                plt.subplot(3, 4, i + 5)\n",
        "                self._show_tensor_image(generated_images[i])\n",
        "                plt.title('Generated')\n",
        "\n",
        "                plt.subplot(3, 4, i + 9)\n",
        "                self._show_tensor_image(target_images[i])\n",
        "                plt.title('Target')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        self.model.train()\n",
        "\n",
        "    def _show_tensor_image(self, tensor):\n",
        "        img = tensor.cpu().detach()\n",
        "        img = img * 0.5 + 0.5\n",
        "        plt.imshow(img.permute(1, 2, 0))\n",
        "        plt.axis('off')\n",
        "\n",
        "    def generate_novel_view(self, source_image, target_pose):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            if not isinstance(source_image, torch.Tensor):\n",
        "                source_image = self.transform(source_image)\n",
        "            source_image = source_image.unsqueeze(0).to(self.device)\n",
        "            target_pose = torch.FloatTensor(target_pose).unsqueeze(0).to(self.device)\n",
        "\n",
        "            generated_image = self.model(source_image, target_pose)\n",
        "\n",
        "            generated_image = generated_image.cpu().squeeze()\n",
        "            generated_image = generated_image * 0.5 + 0.5\n",
        "            generated_image = transforms.ToPILImage()(generated_image)\n",
        "\n",
        "        return generated_image\n",
        "\n",
        "def generate_novel_views(data_loader, num_views=8):\n",
        "    \"\"\"Generate novel views for each object\"\"\"\n",
        "    print(\"Initializing trainer...\")\n",
        "    trainer = MultiViewTrainer(data_loader)\n",
        "\n",
        "    print(\"Training multi-view generation model...\")\n",
        "    trainer.train(num_epochs=100)\n",
        "\n",
        "    print(\"\\nGenerating novel views...\")\n",
        "    for uid in data_loader.dataset:\n",
        "        try:\n",
        "            images, _ = data_loader.load_object_views(uid)\n",
        "            source_image = images[0]\n",
        "\n",
        "            novel_views = []\n",
        "            for i in range(num_views):\n",
        "                angle = (i * 2 * np.pi) / num_views\n",
        "                target_pose = np.array([\n",
        "                    np.cos(angle), np.sin(angle), 0,\n",
        "                    0, 0, 2\n",
        "                ])\n",
        "\n",
        "                novel_view = trainer.generate_novel_view(source_image, target_pose)\n",
        "                novel_views.append(novel_view)\n",
        "\n",
        "            plt.figure(figsize=(20, 4))\n",
        "            for i, view in enumerate(novel_views):\n",
        "                plt.subplot(1, num_views, i + 1)\n",
        "                plt.imshow(view)\n",
        "                plt.axis('off')\n",
        "                plt.title(f'View {i+1}')\n",
        "            plt.suptitle(f'Novel Views for Object {uid}')\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating novel views for object {uid}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "# Test the implementation\n",
        "# if __name__ == \"__main__\":\n",
        "#     # First make sure we have pose estimates\n",
        "#     data_loader = setup_and_test()\n",
        "#     data_loader.estimate_poses()\n",
        "\n",
        "#     # Generate novel views\n",
        "#     print(\"\\nGenerating novel views...\")\n",
        "#     generate_novel_views(data_loader, num_views=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL8KhmPV8tGI",
        "outputId": "d7fbbe6d-e1d6-4c90-d283-02d86fdbcf18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "# First, install dependencies\n",
        "!pip install fvcore iopath\n",
        "!pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
        "!pip install PyMCubes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYfxEr6Ze9gZ",
        "outputId": "e3513a99-44fb-489e-8467-716a8580280b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.26.4)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (10.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath) (4.12.2)\n",
            "Collecting portalocker (from iopath)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=b2d9500deb0fd322f3388eaa25d2b16d54077904cdc18fedd0e13440fbe38e20\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=0135641a3e81b6cad853287228e12952222b8b8afc7e83a8ee5c3f2f9e769d4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.10.1 yacs-0.1.8\n",
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git to /tmp/pip-req-build-v9mw14_y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-v9mw14_y\n",
            "  Resolved https://github.com/facebookresearch/pytorch3d.git to commit 81d82980bc82fd605f27cca87f89ba08af94db3d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from pytorch3d==0.7.8) (0.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d==0.7.8) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d==0.7.8) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d==0.7.8) (2.10.1)\n",
            "Building wheels for collected packages: pytorch3d\n",
            "  Building wheel for pytorch3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch3d: filename=pytorch3d-0.7.8-cp310-cp310-linux_x86_64.whl size=59598855 sha256=47d1b1fcc16cbbfd97f96d6e4681e0bd08ef96496b362dc97f584f2b37940ef7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e4giylzb/wheels/dd/74/cc/b9266c863f19026f796e59a04e1cd9eb3754474a52ce1b66ce\n",
            "Successfully built pytorch3d\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.8\n",
            "Collecting PyMCubes\n",
            "  Downloading PyMCubes-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (868 bytes)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from PyMCubes) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyMCubes) (1.13.1)\n",
            "Downloading PyMCubes-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMCubes\n",
            "Successfully installed PyMCubes-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, install required packages\n",
        "!pip install scikit-image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from skimage import measure\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class SimpleReconstruction3D(nn.Module):\n",
        "    def __init__(self, image_size=512, voxel_size=64):\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.voxel_size = voxel_size\n",
        "\n",
        "        # Feature extraction\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Feature fusion\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(512 * 32 * 32, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, voxel_size * voxel_size * voxel_size),\n",
        "            nn.Sigmoid()  # Added sigmoid to normalize values between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        num_views = x.size(1)\n",
        "\n",
        "        # Reshape input to process all views\n",
        "        x = x.view(batch_size * num_views, 3, self.image_size, self.image_size)\n",
        "\n",
        "        # Extract features\n",
        "        features = self.encoder(x)\n",
        "\n",
        "        # Reshape and fuse features\n",
        "        features = features.view(batch_size, num_views, -1)\n",
        "        features = torch.max(features, dim=1)[0]  # max pooling across views\n",
        "\n",
        "        # Generate 3D volume\n",
        "        volume = self.fusion(features)\n",
        "        volume = volume.view(batch_size, 1, self.voxel_size, self.voxel_size, self.voxel_size)\n",
        "\n",
        "        return volume\n",
        "\n",
        "\n",
        "class Reconstruction3DTrainer:\n",
        "    def __init__(self, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
        "        self.device = device\n",
        "        self.model = SimpleReconstruction3D().to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0001)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((512, 512)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def preprocess_images(self, images):\n",
        "        \"\"\"Preprocess images for the model\"\"\"\n",
        "        processed = []\n",
        "        for img in images:\n",
        "            if isinstance(img, np.ndarray):\n",
        "                img = Image.fromarray(img)\n",
        "            processed.append(self.transform(img))\n",
        "        return torch.stack(processed)\n",
        "\n",
        "    def generate_3d_volume(self, images):\n",
        "        \"\"\"Generate 3D volume from images\"\"\"\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Preprocess images\n",
        "            images_tensor = self.preprocess_images(images)\n",
        "            images_tensor = images_tensor.unsqueeze(0).to(self.device)\n",
        "\n",
        "            # Generate volume\n",
        "            volume = self.model(images_tensor)\n",
        "\n",
        "            # Ensure volume has values between 0 and 1\n",
        "            volume = torch.sigmoid(volume)\n",
        "\n",
        "            return volume.squeeze().cpu().numpy()\n",
        "\n",
        "def volume_to_mesh(volume, threshold=0.5):\n",
        "    \"\"\"Convert volume to mesh using marching cubes\"\"\"\n",
        "    # Ensure volume is correct shape and type\n",
        "    volume = volume.squeeze()\n",
        "    if isinstance(volume, torch.Tensor):\n",
        "        volume = volume.cpu().numpy()\n",
        "\n",
        "    # Print volume statistics for debugging\n",
        "    print(f\"Volume min: {volume.min()}, max: {volume.max()}, mean: {volume.mean()}\")\n",
        "\n",
        "    # Normalize volume to [0, 1] if needed\n",
        "    if volume.min() < 0 or volume.max() > 1:\n",
        "        volume = (volume - volume.min()) / (volume.max() - volume.min())\n",
        "\n",
        "    # Ensure we have some values above and below threshold\n",
        "    if volume.max() <= threshold or volume.min() >= threshold:\n",
        "        print(\"Warning: Volume values don't cross threshold. Adjusting threshold...\")\n",
        "        threshold = (volume.max() + volume.min()) / 2\n",
        "\n",
        "    # Extract surface mesh\n",
        "    try:\n",
        "        verts, faces, normals, values = measure.marching_cubes(volume, threshold)\n",
        "        return verts, faces\n",
        "    except Exception as e:\n",
        "        print(f\"Error in marching cubes: {e}\")\n",
        "        # Try different threshold if original fails\n",
        "        try:\n",
        "            new_threshold = volume.mean()\n",
        "            print(f\"Retrying with threshold = {new_threshold}\")\n",
        "            verts, faces, normals, values = measure.marching_cubes(volume, new_threshold)\n",
        "            return verts, faces\n",
        "        except Exception as e:\n",
        "            print(f\"Second attempt failed: {e}\")\n",
        "            return None, None\n",
        "\n",
        "def plot_volume_slices(volume, num_slices=3):\n",
        "    \"\"\"Visualize slices of the 3D volume\"\"\"\n",
        "    fig, axes = plt.subplots(1, num_slices, figsize=(15, 5))\n",
        "\n",
        "    for i in range(num_slices):\n",
        "        slice_idx = volume.shape[0] // (num_slices + 1) * (i + 1)\n",
        "        axes[i].imshow(volume[slice_idx], cmap='viridis')\n",
        "        axes[i].set_title(f'Slice {slice_idx}')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle('Volume Slices')\n",
        "    plt.show()\n",
        "\n",
        "def reconstruct_3d_shape(data_loader, object_id):\n",
        "    \"\"\"Reconstruct 3D shape for a specific object\"\"\"\n",
        "    try:\n",
        "        # Get images\n",
        "        images, _ = data_loader.load_object_views(object_id)\n",
        "\n",
        "        # Initialize trainer\n",
        "        trainer = Reconstruction3DTrainer()\n",
        "\n",
        "        # Generate 3D volume\n",
        "        volume = trainer.generate_3d_volume(images)\n",
        "\n",
        "        # Convert to mesh\n",
        "        verts, faces = volume_to_mesh(volume)\n",
        "\n",
        "        return verts, faces\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reconstructing shape: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def process_object(data_loader, object_id):\n",
        "    \"\"\"Process a single object\"\"\"\n",
        "    print(f\"\\nProcessing object {object_id}...\")\n",
        "\n",
        "    try:\n",
        "        # Reconstruct shape\n",
        "        verts, faces = reconstruct_3d_shape(data_loader, object_id)\n",
        "\n",
        "        if verts is not None and faces is not None:\n",
        "            # Visualize reconstruction\n",
        "            plot_3d_mesh(verts, faces)\n",
        "            print(\"Reconstruction successful!\")\n",
        "\n",
        "            # Visualize volume slices for debugging\n",
        "            volume = data_loader.dataset[object_id].get('volume', None)\n",
        "            if volume is not None:\n",
        "                plot_volume_slices(volume)\n",
        "        else:\n",
        "            print(\"Reconstruction failed\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing object {object_id}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Test the reconstruction\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting 3D reconstruction...\")\n",
        "\n",
        "    # Get data loader from previous steps\n",
        "    data_loader = setup_and_test()\n",
        "    data_loader.estimate_poses()\n",
        "\n",
        "    # Process first object\n",
        "    first_object_id = list(data_loader.dataset.keys())[0]\n",
        "    process_object(data_loader, first_object_id)\n",
        "\n",
        "    second_object_id = list(data_loader.dataset.keys())[1]\n",
        "    process_object(data_loader, second_object_id)\n",
        "\n",
        "    third_object_id = list(data_loader.dataset.keys())[2]\n",
        "    process_object(data_loader, third_object_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "ecxuBUnvLITa",
        "outputId": "d60aaf2b-65f5-4dea-ee21-71edcf32c9d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Starting 3D reconstruction...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'setup_and_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0ea378870960>\u001b[0m in \u001b[0;36m<cell line: 190>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# Get data loader from previous steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_poses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'setup_and_test' is not defined"
          ]
        }
      ]
    }
  ]
}